{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "!python3 ../information_extraction/utils/split_labelstudio.py \\\n",
    "    --labelstudio_file ./label_output_new/regularized_data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu test on full data\n",
    "!python3 ./information_extraction/model/finetune_adjust_opt.py  \\\n",
    "    --device gpu:0 \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 500 \\\n",
    "    --eval_steps 500 \\\n",
    "    --seed 1000 \\\n",
    "    --model_name_or_path uie-base  \\\n",
    "    --train_path ./information_extraction/data/final_data/training_data.txt \\\n",
    "    --dev_path ./information_extraction/data/final_data/eval_data.txt  \\\n",
    "    --test_path ./information_extraction/data/final_data/testing_data.txt  \\\n",
    "    --max_seq_len 768  \\\n",
    "    --read_data_method chunk \\\n",
    "    --per_device_eval_batch_size 8 \\\n",
    "    --per_device_train_batch_size 8 \\\n",
    "    --multilingual True \\\n",
    "    --num_train_epochs 1 \\\n",
    "    --learning_rate 1.25e-5 \\\n",
    "    --label_names 'start_positions' 'end_positions' \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_export \\\n",
    "    --optimizer \n",
    "    --output_dir ./information_extraction/results/ckp768-seed1000-1.25e-5/ \\\n",
    "    --overwrite_output_dir \\\n",
    "    --disable_tqdm True \\\n",
    "    --metric_for_best_model eval_f1 \\\n",
    "    --load_best_model_at_end  True \\\n",
    "    --save_total_limit 1 \\\n",
    "    --resume_from_checkpoint ./information_extraction/results/checkpoint-768-seed1000-1e-5/checkpoint-8229"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu test on full data\n",
    "!python3 ./information_extraction/model/finetune.py  \\\n",
    "    --device gpu:1 \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 500 \\\n",
    "    --eval_steps 500 \\\n",
    "    --seed 1000 \\\n",
    "    --model_name_or_path uie-base  \\\n",
    "    --train_path ./information_extraction/data/arrange_final_data_mean/training_data.txt \\\n",
    "    --dev_path ./information_extraction/data/arrange_final_data_mean/eval_data.txt  \\\n",
    "    --test_path ./information_extraction/data/arrange_final_data_mean/testing_data.txt  \\\n",
    "    --max_seq_len 512  \\\n",
    "    --read_data_method chunk \\\n",
    "    --per_device_eval_batch_size 16 \\\n",
    "    --per_device_train_batch_size  16 \\\n",
    "    --multilingual True \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --label_names 'start_positions' 'end_positions' \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_export \\\n",
    "    --output_dir ./information_extraction/results/ckp_arrange_data_mean_2e-5_3epoch_512 \\\n",
    "    --overwrite_output_dir \\\n",
    "    --disable_tqdm True \\\n",
    "    --metric_for_best_model eval_f1 \\\n",
    "    --load_best_model_at_end  True \\\n",
    "    --save_total_limit 1 \\\n",
    "    --resume_from_checkpoint ./information_extraction/results/checkpoint-512-seed1000-3e-5/checkpoint-3043"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu test on full data (uie m)\n",
    "!python3 ../information_extraction/model/finetune.py  \\\n",
    "    --device gpu \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 5 \\\n",
    "    --eval_steps 5 \\\n",
    "    --seed 42 \\\n",
    "    --model_name_or_path uie-base  \\\n",
    "    --train_path ../information_extraction/data/training_data.txt \\\n",
    "    --dev_path ../information_extraction/data/eval_data.txt  \\\n",
    "    --max_seq_len 256  \\\n",
    "    --down_sampling_ratio 0 \\\n",
    "    --read_data_method chunk \\\n",
    "    --per_device_eval_batch_size 32 \\\n",
    "    --per_device_train_batch_size  32 \\\n",
    "    --multilingual True \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --learning_rate 1e-5 \\\n",
    "    --label_names 'start_positions' 'end_positions' \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_export \\\n",
    "    --overwrite_output_dir \\\n",
    "    --disable_tqdm True \\\n",
    "    --metric_for_best_model eval_f1 \\\n",
    "    --load_best_model_at_end  True \\\n",
    "    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu test on full data (full content)\n",
    "!python3 ../information_extraction/model/finetune.py  \\\n",
    "    --device gpu \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 100 \\\n",
    "    --eval_steps 100 \\\n",
    "    --seed 42 \\\n",
    "    --model_name_or_path chinese-xlnet-base \\\n",
    "    --train_path ../information_extraction/data/training_data.txt \\\n",
    "    --dev_path ../information_extraction/data/eval_data.txt  \\\n",
    "    --max_seq_len 512  \\\n",
    "    --read_data_method chunk \\\n",
    "    --per_device_eval_batch_size 16 \\\n",
    "    --per_device_train_batch_size  16 \\\n",
    "    --num_train_epochs 5 \\\n",
    "    --learning_rate 1e-5 \\\n",
    "    --label_names 'start_positions' 'end_positions' \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_export \\\n",
    "    --overwrite_output_dir \\\n",
    "    --disable_tqdm True \\\n",
    "    --metric_for_best_model eval_f1 \\\n",
    "    --load_best_model_at_end  True \\\n",
    "    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu test on more_shot_example.json\n",
    "!python3 ../information_extraction/model/finetune.py  \\\n",
    "    --device gpu \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 5 \\\n",
    "    --eval_steps 5 \\\n",
    "    --seed 42 \\\n",
    "    --model_name_or_path ernie-3.0-tiny-nano-v2-zh  \\\n",
    "    --train_path ../information_extraction/data/data_for_more_shot_example/training_data.txt \\\n",
    "    --dev_path ../information_extraction/data/data_for_more_shot_example/eval_data.txt  \\\n",
    "    --max_seq_len 128  \\\n",
    "    --read_data_method chunk \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --per_device_train_batch_size  1 \\\n",
    "    --num_train_epochs 1 \\\n",
    "    --learning_rate 1e-03 \\\n",
    "    --label_names 'start_positions' 'end_positions' \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_export \\\n",
    "    --overwrite_output_dir \\\n",
    "    --disable_tqdm True \\\n",
    "    --metric_for_best_model eval_f1 \\\n",
    "    --load_best_model_at_end  True \\\n",
    "    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu test on more_shot_example.json (full content)\n",
    "!python3 ../information_extraction/model/finetune.py  \\\n",
    "    --device gpu \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50 \\\n",
    "    --eval_steps 50 \\\n",
    "    --seed 42 \\\n",
    "    --model_name_or_path ernie-3.0-tiny-nano-v2-zh  \\\n",
    "    --train_path ../information_extraction/data/data_for_more_shot_example/training_data.txt \\\n",
    "    --dev_path ../information_extraction/data/data_for_more_shot_example/eval_data.txt  \\\n",
    "    --max_seq_len 2048  \\\n",
    "    --read_data_method full \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --per_device_train_batch_size  1 \\\n",
    "    --num_train_epochs 2 \\\n",
    "    --learning_rate 1e-05 \\\n",
    "    --label_names 'start_positions' 'end_positions' \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_export \\\n",
    "    --overwrite_output_dir \\\n",
    "    --disable_tqdm True \\\n",
    "    --metric_for_best_model eval_f1 \\\n",
    "    --load_best_model_at_end  True \\\n",
    "    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu test on full data\n",
    "!python3 ../information_extraction/model/finetune.py  \\\n",
    "    --device gpu \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 100 \\\n",
    "    --eval_steps 100 \\\n",
    "    --seed 42 \\\n",
    "    --model_name_or_path macbert-base-chinese  \\\n",
    "    --train_path ../information_extraction/data/training_data.txt \\\n",
    "    --dev_path ../information_extraction/data/eval_data.txt  \\\n",
    "    --max_seq_len 512  \\\n",
    "    --read_data_method chunk \\\n",
    "    --per_device_eval_batch_size 16 \\\n",
    "    --per_device_train_batch_size  16 \\\n",
    "    --num_train_epochs 5 \\\n",
    "    --learning_rate 1e-5 \\\n",
    "    --resume_from_checkpoint ../information_extraction/results/checkpoint/checkpoint-2064 \\\n",
    "    --label_names 'start_positions' 'end_positions' \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_export \\\n",
    "    --overwrite_output_dir \\\n",
    "    --disable_tqdm True \\\n",
    "    --metric_for_best_model eval_f1 \\\n",
    "    --load_best_model_at_end  True \\\n",
    "    --save_total_limit 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d58828fd0c5f7af717daf8982e0a9ccf3c174b5c7bbe63b6216d1f875908829"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
