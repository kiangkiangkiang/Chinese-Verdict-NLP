{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m[2023-05-10 08:03:40,141] [   DEBUG]\u001b[0m - This dir = /home/ubuntu/work/Chinese-Verdict-NLP/dev\u001b[0m\n",
      "\u001b[32m[2023-05-10 08:03:40,141] [    INFO]\u001b[0m - Converting regularized_data.json into /home/ubuntu/work/Chinese-Verdict-NLP/information_extraction/data/...\u001b[0m\n",
      "\u001b[35m[2023-05-10 08:03:40,181] [   DEBUG]\u001b[0m - in do_split, len(dataset)=363\u001b[0m\n",
      "\u001b[35m[2023-05-10 08:03:40,181] [   DEBUG]\u001b[0m - In convert_format, data len = 290\u001b[0m\n",
      "\u001b[35m[2023-05-10 08:03:40,183] [   DEBUG]\u001b[0m - In convert_format, data len = 37\u001b[0m\n",
      "\u001b[35m[2023-05-10 08:03:40,183] [   DEBUG]\u001b[0m - In convert_format, data len = 36\u001b[0m\n",
      "\u001b[35m[2023-05-10 08:03:40,184] [   DEBUG]\u001b[0m - len(training_data.txt) = 870\u001b[0m\n",
      "\u001b[35m[2023-05-10 08:03:40,317] [   DEBUG]\u001b[0m - len(eval_data.txt) = 111\u001b[0m\n",
      "\u001b[35m[2023-05-10 08:03:40,328] [   DEBUG]\u001b[0m - len(testing_data.txt) = 108\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "!python3 ../information_extraction/utils/split_labelstudio.py \\\n",
    "    --labelstudio_file ./label_output_new/regularized_data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2023-05-10 09:05:05,716] [ WARNING]\u001b[0m - evaluation_strategy reset to IntervalStrategy.STEPS for do_eval is True. you can also set evaluation_strategy='epoch'.\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,716] [    INFO]\u001b[0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,716] [    INFO]\u001b[0m - ============================================================\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,716] [    INFO]\u001b[0m -      Model Configuration Arguments      \u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,716] [    INFO]\u001b[0m - paddle commit id              :4596b9a22540fb0ea5d369c3c804544de61d03d0\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,716] [    INFO]\u001b[0m - export_model_dir              :None\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,716] [    INFO]\u001b[0m - model_name_or_path            :uie-base\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,716] [    INFO]\u001b[0m - multilingual                  :False\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,717] [    INFO]\u001b[0m - \u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,717] [    INFO]\u001b[0m - ============================================================\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,717] [    INFO]\u001b[0m -       Data Configuration Arguments      \u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,717] [    INFO]\u001b[0m - paddle commit id              :4596b9a22540fb0ea5d369c3c804544de61d03d0\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,717] [    INFO]\u001b[0m - dev_path                      :../information_extraction/data/eval_data.txt\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,717] [    INFO]\u001b[0m - max_seq_len                   :512\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,717] [    INFO]\u001b[0m - train_path                    :../information_extraction/data/training_data.txt\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,717] [    INFO]\u001b[0m - \u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,717] [    INFO]\u001b[0m - Process rank: -1, device: gpu, world_size: 1, distributed training: False, 16-bits training: False\u001b[0m\n",
      "\u001b[35m[2023-05-10 09:05:05,751] [   DEBUG]\u001b[0m - Result-Cross.\u001b[0m\n",
      "\u001b[35m[2023-05-10 09:05:05,764] [   DEBUG]\u001b[0m - Result-Cross.\u001b[0m\n",
      "\u001b[35m[2023-05-10 09:05:05,790] [   DEBUG]\u001b[0m - Result-Cross.\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,813] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'uie-base'.\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,813] [    INFO]\u001b[0m - Already cached /home/ubuntu/.paddlenlp/models/uie-base/uie-base/ernie_3.0_base_zh_vocab.txt\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,837] [    INFO]\u001b[0m - tokenizer config file saved in /home/ubuntu/.paddlenlp/models/uie-base/uie-base/tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,837] [    INFO]\u001b[0m - Special tokens file saved in /home/ubuntu/.paddlenlp/models/uie-base/uie-base/special_tokens_map.json\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:05,838] [    INFO]\u001b[0m - Model config ErnieConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"enable_recompute\": false,\n",
      "  \"fuse\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"ernie\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"paddlenlp_version\": null,\n",
      "  \"pool_act\": \"tanh\",\n",
      "  \"task_id\": 0,\n",
      "  \"task_type_vocab_size\": 3,\n",
      "  \"type_vocab_size\": 4,\n",
      "  \"use_task_id\": true,\n",
      "  \"vocab_size\": 40000\n",
      "}\n",
      "\u001b[0m\n",
      "W0510 09:05:07.137326  5806 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.7, Runtime API Version: 10.2\n",
      "W0510 09:05:07.142164  5806 gpu_resources.cc:91] device: 0, cuDNN Version: 8.6.\n",
      "\u001b[32m[2023-05-10 09:05:08,047] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing UIE.\n",
      "\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,048] [    INFO]\u001b[0m - All the weights of UIE were initialized from the model checkpoint at uie-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use UIE for predictions without further training.\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,125] [    INFO]\u001b[0m - ============================================================\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,125] [    INFO]\u001b[0m -     Training Configuration Arguments    \u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,125] [    INFO]\u001b[0m - paddle commit id              :4596b9a22540fb0ea5d369c3c804544de61d03d0\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,125] [    INFO]\u001b[0m - _no_sync_in_gradient_accumulation:True\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,125] [    INFO]\u001b[0m - adam_beta1                    :0.9\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,125] [    INFO]\u001b[0m - adam_beta2                    :0.999\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,125] [    INFO]\u001b[0m - adam_epsilon                  :1e-08\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,125] [    INFO]\u001b[0m - bf16                          :False\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,126] [    INFO]\u001b[0m - bf16_full_eval                :False\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,126] [    INFO]\u001b[0m - current_device                :gpu:0\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,126] [    INFO]\u001b[0m - dataloader_drop_last          :False\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,126] [    INFO]\u001b[0m - dataloader_num_workers        :0\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,126] [    INFO]\u001b[0m - device                        :gpu\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,126] [    INFO]\u001b[0m - disable_tqdm                  :True\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,126] [    INFO]\u001b[0m - do_eval                       :True\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,126] [    INFO]\u001b[0m - do_export                     :True\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,126] [    INFO]\u001b[0m - do_predict                    :False\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,126] [    INFO]\u001b[0m - do_train                      :True\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,126] [    INFO]\u001b[0m - eval_batch_size               :16\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,126] [    INFO]\u001b[0m - eval_steps                    :100\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,126] [    INFO]\u001b[0m - evaluation_strategy           :IntervalStrategy.STEPS\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,126] [    INFO]\u001b[0m - flatten_param_grads           :False\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,126] [    INFO]\u001b[0m - fp16                          :False\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,126] [    INFO]\u001b[0m - fp16_full_eval                :False\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,127] [    INFO]\u001b[0m - fp16_opt_level                :O1\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,127] [    INFO]\u001b[0m - gradient_accumulation_steps   :1\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,127] [    INFO]\u001b[0m - greater_is_better             :True\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,127] [    INFO]\u001b[0m - ignore_data_skip              :False\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,127] [    INFO]\u001b[0m - label_names                   :['start_positions', 'end_positions']\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,127] [    INFO]\u001b[0m - lazy_data_processing          :True\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,127] [    INFO]\u001b[0m - learning_rate                 :1e-05\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,127] [    INFO]\u001b[0m - load_best_model_at_end        :True\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,127] [    INFO]\u001b[0m - local_process_index           :0\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,127] [    INFO]\u001b[0m - local_rank                    :-1\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,127] [    INFO]\u001b[0m - log_level                     :-1\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,127] [    INFO]\u001b[0m - log_level_replica             :-1\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,127] [    INFO]\u001b[0m - log_on_each_node              :True\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,127] [    INFO]\u001b[0m - logging_dir                   :/home/ubuntu/work/Chinese-Verdict-NLP/information_extraction/results/checkpoint/runs/May10_09-05-05_ip-172-31-32-119\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,127] [    INFO]\u001b[0m - logging_first_step            :False\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,127] [    INFO]\u001b[0m - logging_steps                 :10\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,128] [    INFO]\u001b[0m - logging_strategy              :IntervalStrategy.STEPS\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,128] [    INFO]\u001b[0m - lr_scheduler_type             :SchedulerType.LINEAR\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,128] [    INFO]\u001b[0m - max_grad_norm                 :1.0\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,128] [    INFO]\u001b[0m - max_steps                     :-1\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,128] [    INFO]\u001b[0m - metric_for_best_model         :eval_f1\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,128] [    INFO]\u001b[0m - minimum_eval_times            :None\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,128] [    INFO]\u001b[0m - no_cuda                       :False\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,128] [    INFO]\u001b[0m - num_train_epochs              :3.0\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,128] [    INFO]\u001b[0m - optim                         :OptimizerNames.ADAMW\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,128] [    INFO]\u001b[0m - output_dir                    :/home/ubuntu/work/Chinese-Verdict-NLP/information_extraction/results/checkpoint/\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,128] [    INFO]\u001b[0m - overwrite_output_dir          :True\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,128] [    INFO]\u001b[0m - past_index                    :-1\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,128] [    INFO]\u001b[0m - per_device_eval_batch_size    :16\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,128] [    INFO]\u001b[0m - per_device_train_batch_size   :16\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,128] [    INFO]\u001b[0m - prediction_loss_only          :False\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,128] [    INFO]\u001b[0m - process_index                 :0\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,129] [    INFO]\u001b[0m - recompute                     :False\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,129] [    INFO]\u001b[0m - remove_unused_columns         :True\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,129] [    INFO]\u001b[0m - report_to                     :['visualdl']\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,129] [    INFO]\u001b[0m - resume_from_checkpoint        :None\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,129] [    INFO]\u001b[0m - run_name                      :/home/ubuntu/work/Chinese-Verdict-NLP/information_extraction/results/checkpoint/\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,129] [    INFO]\u001b[0m - save_on_each_node             :False\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,129] [    INFO]\u001b[0m - save_steps                    :100\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,129] [    INFO]\u001b[0m - save_strategy                 :IntervalStrategy.STEPS\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,129] [    INFO]\u001b[0m - save_total_limit              :1\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,129] [    INFO]\u001b[0m - scale_loss                    :32768\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,129] [    INFO]\u001b[0m - seed                          :42\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,129] [    INFO]\u001b[0m - sharding                      :[]\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,129] [    INFO]\u001b[0m - sharding_degree               :-1\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,129] [    INFO]\u001b[0m - should_log                    :True\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,129] [    INFO]\u001b[0m - should_save                   :True\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,129] [    INFO]\u001b[0m - skip_memory_metrics           :True\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,130] [    INFO]\u001b[0m - train_batch_size              :16\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,130] [    INFO]\u001b[0m - warmup_ratio                  :0.0\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,130] [    INFO]\u001b[0m - warmup_steps                  :0\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,130] [    INFO]\u001b[0m - weight_decay                  :0.0\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,130] [    INFO]\u001b[0m - world_size                    :1\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,130] [    INFO]\u001b[0m - \u001b[0m\n",
      "\u001b[35m[2023-05-10 09:05:08,130] [   DEBUG]\u001b[0m - chechpoint: None\u001b[0m\n",
      "\u001b[35m[2023-05-10 09:05:08,131] [   DEBUG]\u001b[0m - last_checkpoint: None\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,132] [    INFO]\u001b[0m - ***** Running training *****\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,132] [    INFO]\u001b[0m -   Num examples = 11002\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,132] [    INFO]\u001b[0m -   Num Epochs = 3\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,132] [    INFO]\u001b[0m -   Instantaneous batch size per device = 16\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,132] [    INFO]\u001b[0m -   Total train batch size (w. parallel, distributed & accumulation) = 16\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,132] [    INFO]\u001b[0m -   Gradient Accumulation steps = 1\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,132] [    INFO]\u001b[0m -   Total optimization steps = 2064.0\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,132] [    INFO]\u001b[0m -   Total num train samples = 33006.0\u001b[0m\n",
      "\u001b[32m[2023-05-10 09:05:08,305] [    INFO]\u001b[0m -   Number of trainable parameters = 117946370\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"../information_extraction/model/finetune.py\", line 207, in <module>\n",
      "    finetune(\n",
      "  File \"../information_extraction/model/finetune.py\", line 151, in finetune\n",
      "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddlenlp/trainer/trainer.py\", line 666, in train\n",
      "    tr_loss_step = self.training_step(model, inputs)\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddlenlp/trainer/trainer.py\", line 1329, in training_step\n",
      "    loss = self.compute_loss(model, inputs)\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddlenlp/trainer/trainer.py\", line 1291, in compute_loss\n",
      "    outputs = model(**inputs)\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\n",
      "    return self._dygraph_call_func(*inputs, **kwargs)\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ubuntu/work/Chinese-Verdict-NLP/information_extraction/model/modeling.py\", line 57, in forward\n",
      "    sequence_output, _ = self.ernie(\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\n",
      "    return self._dygraph_call_func(*inputs, **kwargs)\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddlenlp/transformers/ernie/modeling.py\", line 355, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\n",
      "    return self._dygraph_call_func(*inputs, **kwargs)\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddlenlp/transformers/model_outputs.py\", line 295, in _transformer_encoder_fwd\n",
      "    layer_outputs = mod(\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\n",
      "    return self._dygraph_call_func(*inputs, **kwargs)\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddlenlp/transformers/model_outputs.py\", line 82, in _transformer_encoder_layer_fwd\n",
      "    attn_outputs = self.self_attn(src, src, src, src_mask, cache)\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\n",
      "    return self._dygraph_call_func(*inputs, **kwargs)\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddle/nn/layer/transformer.py\", line 400, in forward\n",
      "    q, k, v = self._prepare_qkv(query, key, value, cache)\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddle/nn/layer/transformer.py\", line 234, in _prepare_qkv\n",
      "    k, v = self.compute_kv(key, value)\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddle/nn/layer/transformer.py\", line 268, in compute_kv\n",
      "    k = self.k_proj(key)\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 930, in __call__\n",
      "    return self._dygraph_call_func(*inputs, **kwargs)\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py\", line 915, in _dygraph_call_func\n",
      "    outputs = self.forward(*inputs, **kwargs)\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddle/nn/layer/common.py\", line 171, in forward\n",
      "    out = F.linear(\n",
      "  File \"/home/ubuntu/work/venv_pytorch/lib/python3.8/site-packages/paddle/nn/functional/common.py\", line 1547, in linear\n",
      "    return _C_ops.elementwise_add(pre_bias, bias)\n",
      "SystemError: (Fatal) Operator elementwise_add raises an paddle::memory::allocation::BadAlloc exception.\n",
      "The exception content is\n",
      ":ResourceExhaustedError: \n",
      "\n",
      "Out of memory error on GPU 0. Cannot allocate 24.000000MB memory on GPU 0, 14.604370GB memory has been allocated and available memory is only 17.000000MB.\n",
      "\n",
      "Please check whether there is any other process using GPU 0.\n",
      "1. If yes, please stop them, or start PaddlePaddle on another GPU.\n",
      "2. If no, please decrease the batch size of your model. \n",
      "If the above ways do not solve the out of memory problem, you can try to use CUDA managed memory. The command is `export FLAGS_use_cuda_managed_memory=false`.\n",
      " (at /paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:87)\n",
      ". (at /paddle/paddle/fluid/imperative/tracer.cc:307)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gpu test\n",
    "!python3 ../information_extraction/model/finetune.py  \\\n",
    "    --device gpu \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 100 \\\n",
    "    --eval_steps 100 \\\n",
    "    --seed 42 \\\n",
    "    --model_name_or_path uie-base  \\\n",
    "    --train_path ../information_extraction/data/training_data.txt \\\n",
    "    --dev_path ../information_extraction/data/eval_data.txt  \\\n",
    "    --max_seq_len 512  \\\n",
    "    --per_device_eval_batch_size 16 \\\n",
    "    --per_device_train_batch_size  16 \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --learning_rate 1e-5 \\\n",
    "    --label_names 'start_positions' 'end_positions' \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_export \\\n",
    "    --overwrite_output_dir \\\n",
    "    --disable_tqdm True \\\n",
    "    --metric_for_best_model eval_f1 \\\n",
    "    --load_best_model_at_end  True \\\n",
    "    --save_total_limit 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv_pytorch': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf46acb013efd0588f6afec6d5cfc3a8d59196ff594941befc7df90c31a68b6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
