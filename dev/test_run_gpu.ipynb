{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m[2023-05-10 08:03:40,141] [   DEBUG]\u001b[0m - This dir = /home/ubuntu/work/Chinese-Verdict-NLP/dev\u001b[0m\n",
      "\u001b[32m[2023-05-10 08:03:40,141] [    INFO]\u001b[0m - Converting regularized_data.json into /home/ubuntu/work/Chinese-Verdict-NLP/information_extraction/data/...\u001b[0m\n",
      "\u001b[35m[2023-05-10 08:03:40,181] [   DEBUG]\u001b[0m - in do_split, len(dataset)=363\u001b[0m\n",
      "\u001b[35m[2023-05-10 08:03:40,181] [   DEBUG]\u001b[0m - In convert_format, data len = 290\u001b[0m\n",
      "\u001b[35m[2023-05-10 08:03:40,183] [   DEBUG]\u001b[0m - In convert_format, data len = 37\u001b[0m\n",
      "\u001b[35m[2023-05-10 08:03:40,183] [   DEBUG]\u001b[0m - In convert_format, data len = 36\u001b[0m\n",
      "\u001b[35m[2023-05-10 08:03:40,184] [   DEBUG]\u001b[0m - len(training_data.txt) = 870\u001b[0m\n",
      "\u001b[35m[2023-05-10 08:03:40,317] [   DEBUG]\u001b[0m - len(eval_data.txt) = 111\u001b[0m\n",
      "\u001b[35m[2023-05-10 08:03:40,328] [   DEBUG]\u001b[0m - len(testing_data.txt) = 108\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "!python3 ../information_extraction/utils/split_labelstudio.py \\\n",
    "    --labelstudio_file ./label_output_new/regularized_data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu test on full data\n",
    "!python3 ../information_extraction/model/finetune.py  \\\n",
    "    --device gpu \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 100 \\\n",
    "    --eval_steps 100 \\\n",
    "    --seed 42 \\\n",
    "    --model_name_or_path uie-mini  \\\n",
    "    --train_path ../information_extraction/data/training_data.txt \\\n",
    "    --dev_path ../information_extraction/data/eval_data.txt  \\\n",
    "    --max_seq_len 512  \\\n",
    "    --down_sampling_ratio 0 \\\n",
    "    --read_data_method chunk \\\n",
    "    --per_device_eval_batch_size 32 \\\n",
    "    --per_device_train_batch_size  32 \\\n",
    "    --multilingual True \\\n",
    "    --num_train_epochs 4 \\\n",
    "    --learning_rate 1e-5 \\\n",
    "    --label_names 'start_positions' 'end_positions' \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_export \\\n",
    "    --overwrite_output_dir \\\n",
    "    --disable_tqdm True \\\n",
    "    --metric_for_best_model eval_f1 \\\n",
    "    --load_best_model_at_end  True \\\n",
    "    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu test on full data (uie m)\n",
    "!python3 ../information_extraction/model/finetune.py  \\\n",
    "    --device gpu \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 5 \\\n",
    "    --eval_steps 5 \\\n",
    "    --seed 42 \\\n",
    "    --model_name_or_path uie-base  \\\n",
    "    --train_path ../information_extraction/data/training_data.txt \\\n",
    "    --dev_path ../information_extraction/data/eval_data.txt  \\\n",
    "    --max_seq_len 256  \\\n",
    "    --down_sampling_ratio 0 \\\n",
    "    --read_data_method chunk \\\n",
    "    --per_device_eval_batch_size 32 \\\n",
    "    --per_device_train_batch_size  32 \\\n",
    "    --multilingual True \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --learning_rate 1e-5 \\\n",
    "    --label_names 'start_positions' 'end_positions' \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_export \\\n",
    "    --overwrite_output_dir \\\n",
    "    --disable_tqdm True \\\n",
    "    --metric_for_best_model eval_f1 \\\n",
    "    --load_best_model_at_end  True \\\n",
    "    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu test on full data (full content)\n",
    "!python3 ../information_extraction/model/finetune.py  \\\n",
    "    --device gpu \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50 \\\n",
    "    --eval_steps 50 \\\n",
    "    --seed 42 \\\n",
    "    --model_name_or_path ernie-3.0-base-zh  \\\n",
    "    --train_path ../information_extraction/data/training_data.txt \\\n",
    "    --dev_path ../information_extraction/data/eval_data.txt  \\\n",
    "    --max_seq_len 2048  \\\n",
    "    --read_data_method full \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --per_device_train_batch_size  1 \\\n",
    "    --num_train_epochs 2 \\\n",
    "    --learning_rate 1e-3 \\\n",
    "    --label_names 'start_positions' 'end_positions' \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_export \\\n",
    "    --overwrite_output_dir \\\n",
    "    --disable_tqdm True \\\n",
    "    --metric_for_best_model eval_f1 \\\n",
    "    --load_best_model_at_end  True \\\n",
    "    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu test on more_shot_example.json\n",
    "!python3 ../information_extraction/model/finetune.py  \\\n",
    "    --device gpu \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 5 \\\n",
    "    --eval_steps 5 \\\n",
    "    --seed 42 \\\n",
    "    --model_name_or_path ernie-3.0-tiny-nano-v2-zh  \\\n",
    "    --train_path ../information_extraction/data/data_for_more_shot_example/training_data.txt \\\n",
    "    --dev_path ../information_extraction/data/data_for_more_shot_example/eval_data.txt  \\\n",
    "    --max_seq_len 128  \\\n",
    "    --read_data_method chunk \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --per_device_train_batch_size  1 \\\n",
    "    --num_train_epochs 1 \\\n",
    "    --learning_rate 1e-03 \\\n",
    "    --label_names 'start_positions' 'end_positions' \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_export \\\n",
    "    --overwrite_output_dir \\\n",
    "    --disable_tqdm True \\\n",
    "    --metric_for_best_model eval_f1 \\\n",
    "    --load_best_model_at_end  True \\\n",
    "    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu test on more_shot_example.json (full content)\n",
    "!python3 ../information_extraction/model/finetune.py  \\\n",
    "    --device gpu \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 50 \\\n",
    "    --eval_steps 50 \\\n",
    "    --seed 42 \\\n",
    "    --model_name_or_path ernie-3.0-tiny-nano-v2-zh  \\\n",
    "    --train_path ../information_extraction/data/data_for_more_shot_example/training_data.txt \\\n",
    "    --dev_path ../information_extraction/data/data_for_more_shot_example/eval_data.txt  \\\n",
    "    --max_seq_len 2048  \\\n",
    "    --read_data_method full \\\n",
    "    --per_device_eval_batch_size 1 \\\n",
    "    --per_device_train_batch_size  1 \\\n",
    "    --num_train_epochs 2 \\\n",
    "    --learning_rate 1e-05 \\\n",
    "    --label_names 'start_positions' 'end_positions' \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_export \\\n",
    "    --overwrite_output_dir \\\n",
    "    --disable_tqdm True \\\n",
    "    --metric_for_best_model eval_f1 \\\n",
    "    --load_best_model_at_end  True \\\n",
    "    --save_total_limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu test on full data\n",
    "!python3 ../information_extraction/model/finetune.py  \\\n",
    "    --device gpu \\\n",
    "    --logging_steps 10 \\\n",
    "    --save_steps 100 \\\n",
    "    --eval_steps 100 \\\n",
    "    --seed 42 \\\n",
    "    --model_name_or_path uie-x-base  \\\n",
    "    --train_path ../information_extraction/data/training_data.txt \\\n",
    "    --dev_path ../information_extraction/data/eval_data.txt  \\\n",
    "    --max_seq_len 512  \\\n",
    "    --read_data_method chunk \\\n",
    "    --per_device_eval_batch_size 16 \\\n",
    "    --per_device_train_batch_size  16 \\\n",
    "    --num_train_epochs 5 \\\n",
    "    --learning_rate 1e-5 \\\n",
    "    --label_names 'start_positions' 'end_positions' \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --do_export \\\n",
    "    --overwrite_output_dir \\\n",
    "    --disable_tqdm True \\\n",
    "    --metric_for_best_model eval_f1 \\\n",
    "    --load_best_model_at_end  True \\\n",
    "    --save_total_limit 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
